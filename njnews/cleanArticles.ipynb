{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0044a0165a1a561273ca818f13158b4edea630051cf64f3770cf4dedc4e818f34",
   "display_name": "Python 3.7.9 64-bit ('holcombEnv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from bs4 import BeautifulSoup, element\n",
    "import time as tm\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_remove = \",^\\()|\\\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function constructs the url for an archived webpage according to https://wayback.archive-it.org formatting\n",
    "def get_html(collection_id, folder, data):\n",
    "\n",
    "    # creates a local directory named 'folder' if it doesn't exist\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    # the base url for the archive\n",
    "    ai_url = \"https://wayback.archive-it.org\"\n",
    "\n",
    "    # this gets a unique list of dates and urls so we can avoid duplication\n",
    "    date_list = pd.to_datetime(data['date'].unique())\n",
    "    urls = data['url'].unique()\n",
    "\n",
    "    # this loop iterates through all the urls, searches for the archived webpage\n",
    "    # then looks for any hyperlinks on the page that are associated with a date in the list\n",
    "    for url in urls:\n",
    "\n",
    "        # this is the url of an archived webpage's home \n",
    "        # (e.g. https://wayback.archive-it.org/12706/*/http://mypaperonline.com)\n",
    "        home = ai_url + '/' + str(collection_id) + '/*/' + url\n",
    "\n",
    "        # this block gets all the date hyperlinks\n",
    "        page = requests.get(home)\n",
    "        soup = BeautifulSoup(page.content, \"lxml\")\n",
    "        alist = soup.find_all(\"a\")\n",
    "        alist = [a for a in alist if 'onclick' in a.attrs]\n",
    "        dates = [dt.strptime(a.text, '%b %d, %Y') for a in alist]\n",
    "\n",
    "        # this loops through all the date hyperlinks and if they're in\n",
    "        # the date_list it saves them locally\n",
    "        for a in alist:\n",
    "\n",
    "            # this creates a local path for the html, it converts URLS+dates\n",
    "            # into unique simple strings\n",
    "            path = folder + '/' + dt.strptime(a.text, '%b %d, %Y').strftime('%Y%m%d') + '_' + ''.join(re.findall('(\\d+|[a-zA-Z]+|-|\\.)', url)) + '.html'\n",
    "\n",
    "            if url == 'http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017':\n",
    "                print(path)\n",
    "                print('https:' + a.attrs['href'])\n",
    "                print(dt.strptime(a.text, '%b %d, %Y') in date_list)\n",
    "                print(not os.path.isfile(path))\n",
    "\n",
    "            # this is where it saves the html ('onclick' in a.attrs is probably redundant)\n",
    "            if dt.strptime(a.text, '%b %d, %Y') in date_list and not os.path.isfile(path):\n",
    "                wp = requests.get('https:' + a.attrs['href'])\n",
    "                f = open(path, 'wb')\n",
    "                f.write(wp.content)\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = pd.read_csv('final_chosen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "chosenSamp/20191008_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191008192629/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191012_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191012181003/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191020_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191020191017/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191024_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191024201121/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191030_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191030190212/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191102_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191102020043/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\nchosenSamp/20191111_httpwww.newarkblack.comqueens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017.html\nhttps://wayback.archive-it.org/12706/20191111201820/http://www.newarkblack.com/queens-new-york-annual-pop-shop-artist-market-set-held-multiple-dates-nov-25-2017-december-23-22017/\nTrue\nFalse\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5c90c817c3e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12706\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chosenSamp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchosen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d72eb888c55d>\u001b[0m in \u001b[0;36mget_html\u001b[1;34m(collection_id, folder, data)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# this block gets all the date hyperlinks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0malist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcert_verify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36mcert_verify\u001b[1;34m(self, conn, url, verify, cert)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcert_loc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mcert_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_zipped_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEFAULT_CA_BUNDLE_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcert_loc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcert_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\site-packages\\requests\\utils.py\u001b[0m in \u001b[0;36mextract_zipped_paths\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mjust\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mpath\u001b[0m \u001b[0munchanged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m--> 239\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;31m# this is already a valid path, no need to do anything further\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\holcombEnv\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_html(12706, 'chosenSamp', chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "folder = 'chosenSamp'\n",
    "chosen['cleaned'] = None\n",
    "\n",
    "for index, row in chosen.iterrows():\n",
    "\n",
    "    path = folder + '/' + ''.join(re.findall('\\d+', row.date)) + '_' + ''.join(re.findall('(\\d+|[a-zA-Z]+|-|\\.)', row.url)) + '.html'\n",
    "\n",
    "    f = open(path, 'rb')\n",
    "    soup = BeautifulSoup(f.read(), \"lxml\")\n",
    "    articles = soup.find_all(\"article\")\n",
    "\n",
    "    if len(articles) == 0:\n",
    "        articles = soup.find_all(id = 'op-content')\n",
    "\n",
    "    if len(articles) == 1: \n",
    "        ctr = ctr + 1\n",
    "        text = articles[0].text.translate ({ord(c): \"\" for c in chars_to_remove})\n",
    "        chosen.loc[index, 'text'] = text\n",
    "        chosen.loc[index, 'cleaned'] = 1\n",
    "    else:\n",
    "        chosen.loc[index, 'cleaned'] = 0\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    tm.sleep(.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1832\n"
     ]
    }
   ],
   "source": [
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0        date                 domain  \\\n",
       "0             16  2019-10-08    www.newarkblack.com   \n",
       "1             17  2019-10-08    www.newarkblack.com   \n",
       "2             18  2019-10-08    www.newarkblack.com   \n",
       "3             19  2019-10-08    www.newarkblack.com   \n",
       "4             20  2019-10-08    www.newarkblack.com   \n",
       "...          ...         ...                    ...   \n",
       "2408        4553  2019-11-02  www.mypaperonline.com   \n",
       "2409        4554  2019-11-02  www.mypaperonline.com   \n",
       "2410        4557  2019-11-02  www.mypaperonline.com   \n",
       "2411        4565  2019-11-02  www.mypaperonline.com   \n",
       "2412        4750  2019-10-12  www.mypaperonline.com   \n",
       "\n",
       "                                                    url  \\\n",
       "0                            http://www.newarkblack.com   \n",
       "1                            http://www.newarkblack.com   \n",
       "2     http://www.newarkblack.com/?s={search_term_str...   \n",
       "3                  http://www.newarkblack.com/advertise   \n",
       "4              http://www.newarkblack.com/category/news   \n",
       "...                                                 ...   \n",
       "2408  https://www.mypaperonline.com/first-library-wi...   \n",
       "2409  https://www.mypaperonline.com/hackettstowns-he...   \n",
       "2410  https://www.mypaperonline.com/dont-miss-these-...   \n",
       "2411  http://www.mypaperonline.com/10th-anniversary-...   \n",
       "2412  https://www.mypaperonline.com/hauntings-around...   \n",
       "\n",
       "                                                   text cleaned  \n",
       "0     NewarkBlack.com - Newark African American News...       0  \n",
       "1                                                    �\b       0  \n",
       "2     You searched for {search_term_string} - Newark...       0  \n",
       "3     Advertise - NewarkBlack.com CLOSE Home Adverti...       0  \n",
       "4     News Archives - NewarkBlack.com CLOSE Home Adv...       0  \n",
       "...                                                 ...     ...  \n",
       "2408  Share on FacebookFollow on FacebookAdd to Goog...       1  \n",
       "2409  Share on FacebookFollow on FacebookAdd to Goog...       1  \n",
       "2410  Share on FacebookFollow on FacebookAdd to Goog...       1  \n",
       "2411  Share on FacebookFollow on FacebookAdd to Goog...       1  \n",
       "2412  Share on FacebookFollow on FacebookAdd to Goog...       1  \n",
       "\n",
       "[2413 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>domain</th>\n      <th>url</th>\n      <th>text</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>2019-10-08</td>\n      <td>www.newarkblack.com</td>\n      <td>http://www.newarkblack.com</td>\n      <td>NewarkBlack.com - Newark African American News...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>2019-10-08</td>\n      <td>www.newarkblack.com</td>\n      <td>http://www.newarkblack.com</td>\n      <td>�\b</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18</td>\n      <td>2019-10-08</td>\n      <td>www.newarkblack.com</td>\n      <td>http://www.newarkblack.com/?s={search_term_str...</td>\n      <td>You searched for {search_term_string} - Newark...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19</td>\n      <td>2019-10-08</td>\n      <td>www.newarkblack.com</td>\n      <td>http://www.newarkblack.com/advertise</td>\n      <td>Advertise - NewarkBlack.com CLOSE Home Adverti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>2019-10-08</td>\n      <td>www.newarkblack.com</td>\n      <td>http://www.newarkblack.com/category/news</td>\n      <td>News Archives - NewarkBlack.com CLOSE Home Adv...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>4553</td>\n      <td>2019-11-02</td>\n      <td>www.mypaperonline.com</td>\n      <td>https://www.mypaperonline.com/first-library-wi...</td>\n      <td>Share on FacebookFollow on FacebookAdd to Goog...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2409</th>\n      <td>4554</td>\n      <td>2019-11-02</td>\n      <td>www.mypaperonline.com</td>\n      <td>https://www.mypaperonline.com/hackettstowns-he...</td>\n      <td>Share on FacebookFollow on FacebookAdd to Goog...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>4557</td>\n      <td>2019-11-02</td>\n      <td>www.mypaperonline.com</td>\n      <td>https://www.mypaperonline.com/dont-miss-these-...</td>\n      <td>Share on FacebookFollow on FacebookAdd to Goog...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>4565</td>\n      <td>2019-11-02</td>\n      <td>www.mypaperonline.com</td>\n      <td>http://www.mypaperonline.com/10th-anniversary-...</td>\n      <td>Share on FacebookFollow on FacebookAdd to Goog...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>4750</td>\n      <td>2019-10-12</td>\n      <td>www.mypaperonline.com</td>\n      <td>https://www.mypaperonline.com/hauntings-around...</td>\n      <td>Share on FacebookFollow on FacebookAdd to Goog...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2413 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen.drop('Unnamed: 0', axis=1).to_csv('cleaned1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}