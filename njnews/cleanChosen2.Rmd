---
title: "Chosen Sample"
author: "Matthew Bone"
date: "5/4/2021"
output: 
  html_document:
    fig_height: 3
    fig_width: 5
  pdf_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
---

This report takes a look the chosen sample from 12706-fulltext.txt. The sample includes webpages that are from the domains below and from the dates below. In a post extraction step, "mypaperonline" webpages were filtered for if they have "category/the-morristown-news" or if webpage's HTML has an article object that is labeled with "cateogry-the-morristown-news" or "category-morristown-digital-edition".

**Domains filtered on:**

'https://www.mypaperonline.com' 

'https://www.newbrunswicktoday.com'

'https://www.newarkblack.com'

'http://www.mypaperonline.com'

'http://www.newbrunswicktoday.com'

'http://www.newarkblack.com'

'https://mypaperonline.com' 

'https://newbrunswicktoday.com'

'https://newarkblack.com'

'http://mypaperonline.com'

'http://newbrunswicktoday.com'

'http://newarkblack.com'

'mypaperonline.com'

'newbrunswicktoday.com'

'newarkblack.com'

'www.mypaperonline.com'

'www.newbrunswicktoday.com'

'www.newarkblack.com'

**Dates filtered on:**

'20191008'

'20191012'

'20191020'

'20191024'

'20191030'

'20191101'

'20191111'

'20190930'

'20191001'

'20191002' *None*

'20191003' *None*

'20191004' *None*

```{r, setup, include=FALSE}
library(readr)
library(kableExtra)
library(tidyverse)
library(ggformula)
library(scales)
library(cld3)
library(stringr)
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

```{r, include=FALSE}
chosen <- read_csv('final_chosen.csv')
```

```{r, include=FALSE}
n_entries <- chosen %>%
  nrow()

n_dom <- chosen %>%
  select(domain) %>%
  unique() %>%
  nrow()

n_url <- chosen %>%
  select(url) %>%
  unique() %>%
  nrow()
```

## Quick Numbers

Number of Articles: `r n_entries`

Number of Unique Domains: `r n_dom`

Number of Unique URLs: `r n_url`

```{r, include=FALSE}
samp <- chosen %>% 
  head()
```

```{r, echo=FALSE}
samp
```
## Counts by Domain

```{r, include=FALSE}
counts <- chosen %>%
  group_by(domain) %>%
  summarize(count = n()) %>%
  arrange(domain)  %>%
  kable(format = "markdown")
```

```{r, echo=FALSE}
counts 
```

## Counts by Date and Domain

```{r, include=FALSE}
counts <- chosen %>%
  group_by(date, domain) %>%
  summarize(count = n()) %>%
  arrange(date)  %>%
  kable(format = "markdown")
```

```{r, echo=FALSE}
counts 
```


## Date Distribution

```{r, echo=FALSE}
chosen %>%
  gf_bar(~date)
```

# Filtered by Domains but not Dates

I additionally extracted all data from the given websites (filtered on domain list above) to see if there's a significant amount of data to be used on other dates.

```{r, include=FALSE}
all_dates <- read_csv('final_chosen_alldates.csv')
```

```{r, include=FALSE}
n_entries <- all_dates %>%
  nrow()

n_dom <- all_dates %>%
  select(domain) %>%
  unique() %>%
  nrow()

n_url <- all_dates %>%
  select(url) %>%
  unique() %>%
  nrow()
```

## Quick Numbers

Number of Articles: `r n_entries`

Number of Unique Domains: `r n_dom`

Number of Unique URLs: `r n_url`

```{r, include=FALSE}
samp <- all_dates %>% 
  head()
```

```{r, echo=FALSE}
samp
```

## Counts by Domain

```{r, include=FALSE}
counts <- all_dates %>%
  group_by(domain) %>%
  summarize(count = n()) %>%
  arrange(domain)  %>%
  kable(format = "markdown")
```

```{r, echo=FALSE}
counts 
```

## Counts by Date and Domain

```{r, include=FALSE}
counts <- all_dates %>%
  group_by(date, domain) %>%
  summarize(count = n()) %>%
  arrange(date) %>%
  kable(format = "markdown")
```

```{r, echo=FALSE}
counts 
```

## Date Distribution

```{r, echo=FALSE}
all_dates %>%
  gf_bar(~date)
```

